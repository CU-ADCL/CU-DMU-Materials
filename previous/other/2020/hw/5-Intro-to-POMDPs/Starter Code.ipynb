{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling POMDPSimulators [e0d0a172-29c6-5d4e-96d0-f262df5d01fd]\n",
      "└ @ Base loading.jl:1273\n"
     ]
    }
   ],
   "source": [
    "using POMDPs\n",
    "using POMDPModels\n",
    "using POMDPModelTools\n",
    "using BeliefUpdaters\n",
    "using POMDPPolicies\n",
    "using POMDPSimulators\n",
    "using QuickPOMDPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "For problem 1, you may wish to use a belief updater:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m         DiscreteBelief{BabyPOMDP,Bool} distribution\u001b[22m\n",
      "\u001b[90m         ┌                                        ┐\u001b[39m \n",
      "   \u001b[0mfalse\u001b[90m ┤\u001b[39m\u001b[32m■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\u001b[39m\u001b[0m 1.0 \u001b[90m \u001b[39m \n",
      "    \u001b[0mtrue\u001b[90m ┤\u001b[39m\u001b[0m 0.0                                    \u001b[90m \u001b[39m \n",
      "\u001b[90m         └                                        ┘\u001b[39m \n",
      "\u001b[1m         DiscreteBelief{BabyPOMDP,Bool} distribution\u001b[22m\n",
      "\u001b[90m         ┌                                        ┐\u001b[39m \n",
      "   \u001b[0mfalse\u001b[90m ┤\u001b[39m\u001b[32m■■■■■■■■■■■■■■■■■■■■\u001b[39m\u001b[0m 0.9759036144578314 \u001b[90m \u001b[39m \n",
      "    \u001b[0mtrue\u001b[90m ┤\u001b[39m\u001b[0m 0.02409638554216867                    \u001b[90m \u001b[39m \n",
      "\u001b[90m         └                                        ┘\u001b[39m \n",
      "\u001b[1m         DiscreteBelief{BabyPOMDP,Bool} distribution\u001b[22m\n",
      "\u001b[90m         ┌                                        ┐\u001b[39m \n",
      "   \u001b[0mfalse\u001b[90m ┤\u001b[39m\u001b[32m■■■■■■■■■■■■■■■■■■■■\u001b[39m\u001b[0m 0.9701315984030756 \u001b[90m \u001b[39m \n",
      "    \u001b[0mtrue\u001b[90m ┤\u001b[39m\u001b[32m■\u001b[39m\u001b[0m 0.029868401596924433                  \u001b[90m \u001b[39m \n",
      "\u001b[90m         └                                        ┘\u001b[39m \n"
     ]
    }
   ],
   "source": [
    "# You can construct a standard crying baby POMDP model like this\n",
    "r_feed = -5.0\n",
    "r_hungry = -10.0\n",
    "p_become_hungry = 0.1\n",
    "p_cry_when_hungry = 0.8\n",
    "p_cry_when_not_hungry = 0.1\n",
    "γ = 0.9\n",
    "m = BabyPOMDP(r_feed, r_hungry,\n",
    "              p_become_hungry,\n",
    "              p_cry_when_hungry,\n",
    "              p_cry_when_not_hungry,\n",
    "              γ\n",
    "             )\n",
    "\n",
    "# states, actions, and observations are represented by Bools\n",
    "# true = feed, crying, hungry, etc.\n",
    "\n",
    "# then you can do belief updates as follows\n",
    "up = DiscreteUpdater(m)\n",
    "b = initialize_belief(up, Deterministic(false))\n",
    "showdistribution(b); println()\n",
    "a = false; o = false\n",
    "b = update(up, b, a, o)\n",
    "showdistribution(b); println()\n",
    "b = update(up, b, a, o)\n",
    "showdistribution(b); println()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "For Problem 2, you should create a model of the problem using QuickPOMDPs.\n",
    "\n",
    "An example of the Tiger POMDP, but modified so that the initial state distribution/belief is that the tiger is definitely behind the left door.\n",
    "\n",
    "See the `DiscreteExplicitPOMDP` docstring for more information including information about terminal states.\n",
    "\n",
    "Note that for a more compact representation, you may want to use [`QuickPOMDP`](https://juliapomdp.github.io/QuickPOMDPs.jl/stable/quick/) ([example](https://github.com/JuliaPOMDP/QuickPOMDPs.jl/blob/master/examples/lightdark.jl)) rather than `DiscreteExplicitPOMDP`, but this requires a little more knowledge of Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [:left, :right]\n",
    "A = [:left, :right, :listen]\n",
    "O = [:left, :right]\n",
    "γ = 0.95\n",
    "\n",
    "function T(s, a, sp)\n",
    "    if a == :listen\n",
    "        return s == sp\n",
    "    else # a door is opened\n",
    "        return 0.5 #reset\n",
    "    end\n",
    "end\n",
    "\n",
    "function Z(a, sp, o)\n",
    "    if a == :listen\n",
    "        if o == sp\n",
    "            return 0.85\n",
    "        else\n",
    "            return 0.15\n",
    "        end\n",
    "    else\n",
    "        return 0.5\n",
    "    end\n",
    "end\n",
    "\n",
    "function R(s, a)\n",
    "    if a == :listen  \n",
    "        return -1.0\n",
    "    elseif s == a # the tiger was found\n",
    "        return -100.0\n",
    "    else # the tiger was escaped\n",
    "        return 10.0\n",
    "    end\n",
    "end\n",
    "\n",
    "b₀ = Deterministic(:left)\n",
    "\n",
    "m = DiscreteExplicitPOMDP(S,A,O,T,Z,R,γ,b₀);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the model, you can define policies. By default if you use a `FunctionPolicy`, it will get the previous observation as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-949.3876979559959"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_based_policy = FunctionPolicy(\n",
    "    function (o)\n",
    "        if o == :left\n",
    "            return :right\n",
    "        else\n",
    "            return :left\n",
    "        end\n",
    "    end\n",
    ")\n",
    "\n",
    "rsum = 0.0\n",
    "N = 100_000\n",
    "for i in 1:N\n",
    "    sim = RolloutSimulator(max_steps=100)\n",
    "    rsum += simulate(sim, m, obs_based_policy)\n",
    "end\n",
    "rsum/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also feed back on the belief by specifying a belief updater in the `simulate` function call. Use the POMDPs.jl [Distribution Interface](http://juliapomdp.github.io/POMDPs.jl/stable/interfaces/#Distributions-1) to interact with the belief:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "belief_based_policy = FunctionPolicy(\n",
    "    function (b)\n",
    "        if pdf(b, :left) > 0.95\n",
    "            return :right\n",
    "        elseif pdf(b, :right) > 0.95\n",
    "            return :left\n",
    "        else\n",
    "            return :listen\n",
    "        end\n",
    "    end\n",
    ")\n",
    "\n",
    "up = DiscreteUpdater(m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.35926829324021"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsum = 0.0\n",
    "N = 100_000\n",
    "for i in 1:N\n",
    "    sim = RolloutSimulator(max_steps=100)\n",
    "    rsum += simulate(sim, m, belief_based_policy, up)\n",
    "end\n",
    "rsum/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
