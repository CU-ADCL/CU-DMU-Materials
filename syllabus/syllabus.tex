\documentclass[9pt]{article}

\usepackage{fullpage}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{multicol}
% \usepackage[normalem]{ulem}

\addtolength{\topmargin}{-.25in}
\addtolength{\textheight}{0.5in}
% \setlength{\parindent}{0pt}
\setlength{\multicolsep}{2pt}

\title{ASEN/CSCI 5264: Decision Making under Uncertainty}
\author{Zachary Sunberg}
\date{Spring 2024}

\begin{document}

\maketitle

\section*{Prerequisites}

\begin{itemize}[nosep]
    \item Basic familiarity with probability
    \item Fluency in a high level programming language and willingness to learn Julia.
\end{itemize}

\section*{Rough Schedule and List of Topics}

(See Piazza for detailed and updated schedule.)

\begin{enumerate}[noitemsep]
    \item \textbf{Probabilistic Models}:
        \begin{multicols}{2}
            \begin{itemize}[noitemsep]
                \item Probability
                \item Conditional probability
                \item Markov processes
                \item Introduction to Bayesian networks
            \end{itemize}
        \end{multicols}
    \item \textbf{Markov Decision Processes}:
        \begin{multicols}{2}
        \begin{itemize}[noitemsep]
            \item Markov decision processes (MDPs)
            \item Value iteration (contraction proof of convergence)
            \item Policy iteration
            \item Approximate dynamic programming
            \item Online tree search
        \end{itemize}
        \end{multicols}
    \item \textbf{Reinforcement Learning}:
        \begin{multicols}{2}
        \begin{itemize}[noitemsep]
            \item Exploration and exploitation
            \item Bandits
            \item Model-free RL
            \item Model-based RL
            \item Deep Q learning
            \item Policy gradient
            \item Actor-critic
            \item Entropy Regularization
        \end{itemize}
        \end{multicols}
    \item \textbf{POMDPs}:
        \begin{multicols}{2}
        \begin{itemize}[noitemsep]
            \item Hidden Markov models
            \item Bayesian filters
            \item Particle filters
            \item Partially observable Markov decision processes (POMDPs)
            \item Exact POMDP methods
            \item Offline POMDP methods
            \item Online POMDP methods
            \item QMDP
        \end{itemize}
        \end{multicols}
    \item \textbf{Other Topics}:
        \begin{multicols}{2}
        \begin{itemize}[noitemsep]
            \item Games and multi-agent interaction
            \item Meta and transfer learning
            \item State of the art overview (e.g. Recent Deep RL Algorithms)
        \end{itemize}
        \end{multicols}
\end{enumerate}

\begin{samepage}
\section*{Websites}

\begin{itemize}[nosep]
    \item \href{https://piazza.com}{\textbf{Piazza}} will host course discussions, announcements, and host solutions that are not posted publicly. Students are encouraged to ask questions here. Rather than emailing questions to the teaching staff, I encourage you to post your questions on Piazza. The class signup link is at \url{https://piazza.com/colorado/spring2024/asen5264}.
    \item \textbf{Gradescope} will be used for all assignments and exams.
    \item \href{https://github.com/CU-ADCL/CU-DMU-Materials}{\textbf{Github}} will be used to host all course materials.
\end{itemize}

\end{samepage}

\section*{Attendance and Participation}

Learning is a collaborative effort between the instructor and students. If students are registered for the in-person section, they are expected to attend class and participate in discussions and exercises. Remote students are expected to watch the recorded lectures, ask questions on the Piazza discussion board if there is confusion, and monitor course announcements delivered via Piazza or email.

\section*{Textbook}

\textbf{Mykel J. Kochenderfer, Tim A. Wheeler, and Kyle H. Wray, \textit{Algorithms for Decision Making}}. 2020. Available Online: \url{http://algorithmsbook.com}. \$95.00.

\subsection*{Additional References}

\begin{itemize}[noitemsep]
    \item Richard S. Sutton and Andrew G. Barto, \textit{Reinforcement Learning: An Introduction}, 2nd Ed. MIT Press, 2018. \$80.00, Available online: \url{http://incompleteideas.net/book/the-book-2nd.html}
    \item Dimitri P. Bertsekas, \textit{Dynamic Programming and Optimal Control}, Athena Scientific, 2012 (4th Ed.). \$134.50
    \item Mykel J. Kochenderfer, \textit{Decision Making Under Uncertainty: Theory and Application}, MIT Press, 2015. \$70.00, Available online: \url{https://ieeexplore.ieee.org/book/7288640}
    \item Tom Kwong, \textit{Hands-On Design Patterns and Best Practices with Julia}, Packt Publishing, 2020. \$39.99
    \item Stefano Albrecht, Filippos Christianos, and Lukas Schafer, \textit{Multi-Agent Reinforcement Learning: Foundations and Modern Approaches}. Available online: \url{https://www.marl-book.com/}
    \item Laura Graesser, Wah Loon Keng, \textit{Foundations of Deep Reinforcement Learning: Theory and Practice in Python}. Pearson Education, 2020. \$50.00.
\end{itemize}


\begin{samepage}
\section*{Assignments and Grading}

\begin{itemize}[noitemsep]
    \item \textbf{40\% Homework Assignments.}
There will be 6 large homework assignments, due approximately every two weeks. A typical assignment will consist of
\begin{itemize}[nosep]
    \item Several conceptual questions or exercises.
    \item One open-ended programming problem. You solution will be evaluated locally with obfuscated code and the score submitted to a leaderboard. The best performers will share their solution in class.
\end{itemize}

\item \textbf{30\% Exams.}
There will be three Exams consisting of several conceptual questions or exercises. Each exam will be taken remotely and timed for approximately 90 minutes. You will have a 24hr period within which to take the exam.

\item \textbf{30\% Final Project.}
A final project chosen by the student that ideally connects to their research. Deliverable will be a 4-8 page report. Project may be completed in teams of up to 3.
\end{itemize}
As of the beginning of the course, participation is not expected to be a factor in assigning grades, however it may become a factor at the instructor's discretion. The class will be notified if participation from that point forward will be considered.
\end{samepage}

\subsection*{Late Policy}

To ensure proper progression through the course, students are expected to begin assignments early and submit homework assignments on time. However, in order to provide for minor unforeseen events or responsibilities, students may turn in late homework assignments within 72 hours of the due date with a 10\% penalty without any questions asked.

Exams must be turned in on time. If there is a technical error that causes you to miss the deadline, email me with images of the exam \textbf{immediately} so that I have a record of when you finished the exam. Penalties for missing an exam or final project deadline will be determined on a case-by-case basis.

If a student has a special circumstance such as a major medical procedure, major family responsibility, or a religious observance that will prevent them from completing course work on time, this should be coordinated with the instructor before the due date.

\section*{Course Staff}

\begin{multicols}{2}
    \begin{minipage}{\columnwidth}
        \textbf{Instructor}: Professor Zachary Sunberg\\
        AERO 263 \href{mailto://zachary.sunberg@colorado.edu}{zachary.sunberg@colorado.edu}\\
        \textbf{Office Hours}: Posted on Piazza
    \end{minipage}

    \begin{minipage}{\columnwidth}
        \textbf{Teaching Assistant}: Ben Chupik\\
        \href{mailto://benjamin.chupik@colorado.edu}{benjamin.chupik@colorado.edu}\\
        \textbf{Office Hours}: Posted on Piazza
    \end{minipage}
\end{multicols}

\section*{Meetings}

T/TH 11:30-12:45, AERO 111 -- Lecture video will automatically be posted online after class - see Piazza for link.

\section*{Additional Policies}

{\small
    \input{required.tex}
}
\end{document}
